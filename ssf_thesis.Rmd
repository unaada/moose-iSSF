---
title: "ssf_thesis"
author: "Una Adamoviča"
date: "2025-03-05"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE, include = FALSE)
library(suncalc)
library(chron)

library(sf)
library(terra)
library(tidyverse)
library(lubridate)
library(corrplot)

library(amt)
library(glmmTMB)

```



```{r adding time period of crossing location}

time <- read.csv("D:\\Users\\amand\\Documents\\qgis\\masters_qgis\\vectors\\crossing_time\\intersections_distance.csv")

# make conversions to do operations
time <- time %>%
  mutate(
    start_h = chron(times = start_h),
    end_h = chron(times = end_h),
    d_start = as.Date(d_start, format = "%Y/%m/%d")
  )

# find the time of crossing through linear interpolation 
time$interpolated_time <- time$start_h + 
  (time$distance_to_start / time$distance_of_track) * (time$end_h - time$start_h)

final <- left_join(time, sunlight, join_by("d_start" == "date") , relationship = "many-to-many", multiple = "first")


#need to check the coordinates more precisely
sunlight <- getSunlightTimes(date = final$d_start, lon = 25.45, lat = 59.05, 
                             keep = c("sunriseEnd", "sunset", "night", "nightEnd"),
                             tz = "Europe/Tallinn" )

# get the light times
sun_times <- c("sunriseEnd", "sunset", "night", "nightEnd")
final[sun_times] <- lapply(final[sun_times], function(x) chron(times = format(x, format = "%H:%M:%S")))


final <- final %>%
  mutate(
    time_category = case_when(
      interpolated_time >= sunriseEnd & interpolated_time < sunset  ~ "Day",
      interpolated_time >= night | interpolated_time < nightEnd  ~ "Night",
      .default = "Twilight"
      ),
    crossing_time = lubridate::hms(interpolated_time)
  )


head(final, 5)
```

```{r workflow}

### collect covariates
# distance to road per class
# land cover: different forest types, open, anthropogenic, water, new forest
# time of day:distance_to_road and time:crossing(y/n)
# season - after decding which models, then build for 3 seasons?
# -- perhaps -- make also the angle analysis = avoidance, attraction, corridor

### remove biased data potentially due to capture stress ??




```



```{r preperation of moose data, echo=TRUE}

moose <- read.csv("moose_df.csv")

# clean and make tracks 
moose <- moose %>% 
  mutate(timestamp = as.POSIXct(as.character(timestamp),  format = "%Y-%m-%d %H:%M:%S")) %>%
  filter(!is.na(timestamp)) %>% 
  make_track(UTM.Easting, UTM.Northing, timestamp, crs = 3301, id = id)

head(moose, 5)

# # A tibble: 5 × 4
#        x_       y_ t_                     id
# *   <dbl>    <dbl> <dttm>              <int>
# 1 591225. 6545176. 2018-11-23 22:30:18 39789
# 2 591250. 6545167. 2018-11-23 23:00:08 39789
# 3 591337. 6545008. 2018-11-23 23:30:16 39789
# 4 591292. 6544921. 2018-11-24 00:00:11 39789
# 5 591238. 6545135. 2018-11-24 00:30:30 39789

summarize_sampling_rate_many(moose, "id")

# make manipulations of moose data
moose_sf <- st_as_sf(moose, coords = c("x_", "y_"), crs = 3301) 

# create lines
moose_lines <- moose_sf %>%
  group_by(id) %>%
  summarize(do_union = FALSE) %>%
  st_cast("LINESTRING")
plot(moose_lines)

# create study area to clip everyhting
study_area <- moose_sf %>%
  st_buffer(dist = 1823) %>%
  st_union() %>%
  st_as_sf()

# remove the points when animals are resting
points_to_keep <- moose_sf %>%
  group_by(id) %>%
  mutate(
    distance = as.numeric(st_distance(geometry, lead(geometry), by_element = TRUE)),
    keep_point = !is.na(distance) & distance > 18
  ) %>%
  pull(keep_point)

moose_filter <- moose[points_to_keep, ]
head(moose_filter, 5)

# > head(moose_filter, 5)
# # A tibble: 5 × 4
#        x_       y_ t_                     id
# *   <dbl>    <dbl> <dttm>              <int>
# 1 591225. 6545176. 2018-11-23 22:30:18 39789
# 2 591250. 6545167. 2018-11-23 23:00:08 39789
# 3 591337. 6545008. 2018-11-23 23:30:16 39789
# 4 591292. 6544921. 2018-11-24 00:00:11 39789
# 5 591238. 6545131. 2018-11-24 03:00:15 39789

# list-column to make it easy to apply functions to each animal data seperately 
dat1 <- moose_filter %>% nest(data = -id)
head(dat1,8)

# > head(dat1,8)
# # A tibble: 8 × 2
#      id data                  
#   <int> <list>                
# 1 39789 <trck_xyt [4,548 × 3]>
# 2 39787 <trck_xyt [6,073 × 3]>
# 3 39785 <trck_xyt [5,870 × 3]>
# 4 39788 <trck_xyt [5,140 × 3]>
# 5 39793 <trck_xyt [5,894 × 3]>
# 6 39791 <trck_xyt [5,780 × 3]>
# 7 39790 <trck_xyt [5,464 × 3]>
# 8 39794 <trck_xyt [6,430 × 3]>

# resample to have everything consistent
dat2 <- dat1 %>% 
  mutate(dat.resample = map(data, ~ track_resample(., 
                                                   rate = lubridate::minutes(30), 
                                                   tolerance = lubridate::minutes(2)))) 

head(dat2)
```


```{r collecting covariates}
#layers

new_forest <- rast("D:\\Users\\amand\\Documents\\qgis\\masters_data\\Hansen_GFC-2022-v1.10_lossyear_60N_020E.tif")

roads <- st_read("D:\\Users\\amand\\Documents\\qgis\\masters_qgis\\vectors\\full-road-classes.gpkg")

corine <- rast("D:\\Users\\amand\\Documents\\qgis\\masters_qgis\\rasters\\corine_30m_resample_mode.tif")

#### 1. landuse
# reclassify matrix to group landuse categories
m <- matrix(c(0,22,1,
              22,23, 2,
              23, 24, 3,
              24, 25, 4,
              25, 41, 5), ncol = 3, byrow = TRUE)

# 1 = human-modified = agriculture and anthropogenic
# 2 = broad-leaved (deciduous)
# 3 = coniferous
# 4 = mixed
# 5 = open areas -> combine with srub and peatbog and water
# lowest excluded, maximum included

landuse <- terra::classify(corine, m) %>%
  crop(study_area) %>% 
  mask(study_area) %>% 
  setNames("landuse")

#### 2. roads + distance
# distance to roads code
  # mutate(
  #   nearest_major = st_distance(geometry,st_union(roads[roads$class>= 2, ])),
  #   nearest_minor = st_distance(geometry, st_union(roads[roads$class== 1, ])),
  #   nearest_local = st_distance(geometry, st_union(roads[roads$class == 0, ]))
  # )

major_roads_dist <- roads[roads$class >= 2,] %>%
  rasterize(landuse) %>%
  distance() %>% 
  crop(study_area) %>% 
  mask(study_area) %>% 
  setNames("major_d")

minor_roads_dist <- roads[roads$class == 1,] %>%
  rasterize(landuse) %>%
  distance() %>% 
  crop(study_area) %>% 
  mask(study_area) %>% 
  setNames("minor_d")

local_roads_dist <- roads[roads$class == 0,] %>%
  rasterize(landuse) %>%
  distance() %>% 
  crop(study_area) %>% 
  mask(study_area) %>% 
  setNames("local_d")


#### 3. new forest (forest loss)
# reproject the layer, align the grids, and assign binary values to have new forest y/n
new_forest <- new_forest %>% 
  project(landuse) %>% 
  resample(landuse, method = "near") %>% 
  classify(matrix(c(0, 16, 1,
                    16, 22, 0), ncol = 3, byrow = TRUE)) %>% 
  crop(study_area) %>% 
  mask(study_area) %>% 
  setNames("new_forest")


#### 4. time 



```



```{r 1 moose}
test_moose <- dat2$dat.resample[[1]] %>% 
  filter_min_n_burst(min_n = 3)

steps <- test_moose %>%
  steps_by_burst() %>%
  random_steps(n_control = 10, 
              sl_distr = fit_distr(.$sl_, "gamma"),
              ta_distr = fit_distr(.$ta_, "vonmises"), 
              include_observed = TRUE)
#verify
table(steps$case_)

##### add lines later , doe not work
# # STEP 2: Create lines for crossing detection
# step_lines <- steps %>%
#   steps_to_lines() %>%
#   st_as_sf()

# extrack raster covariates one by one
steps2 <- steps %>% 
  extract_covariates(landuse) %>% 
  extract_covariates(new_forest) %>% 
  extract_covariates(major_roads_dist) %>%
  extract_covariates(minor_roads_dist) %>%
  extract_covariates(local_roads_dist)

###### add crossings later
# 
# steps_with_crossings <- steps_with_roads %>%
#   mutate(
#     crosses_major = lengths(st_intersects(step_lines, roads[roads$class >= 2, ])) > 0,
#     crosses_minor = lengths(st_intersects(step_lines, roads[roads$class == 1, ])) > 0,
#     crosses_local = lengths(st_intersects(step_lines, roads[roads$class == 0, ])) > 0
#   )


# time categories
steps3 <- steps2 %>%
  mutate(
    time_of_day = chron(times = format(t1_, format = "%H:%M:%S")),
    date = as.Date(t1_, format = "%Y/%m/%d")
  ) 

sunlight <- getSunlightTimes(
  date = steps3$date,
  lon = 25.45, 
  lat = 59.05, 
  keep = c("sunrise", "sunset", "dawn", "dusk"),
  tz = "Europe/Tallinn"
)

steps3 <- steps3 %>%
  left_join(sunlight, by = "date", relationship = "many-to-many", multiple = "first") %>%
  mutate(
    sunrise = chron(times = format(sunrise, format = "%H:%M:%S")),
    sunset = chron(times = format(sunset, format = "%H:%M:%S")),
    dawn = chron(times = format(dawn, format = "%H:%M:%S")),
    dusk = chron(times = format(dusk, format = "%H:%M:%S")),
    
    time_category = case_when(
      time_of_day >= sunrise & time_of_day < sunset ~ 1, # day
      (time_of_day >= dawn & time_of_day < sunrise) | 
        (time_of_day >= sunset & time_of_day < dusk) ~ 2, # twilight
      TRUE ~ 3), #night
    
    month = lubridate::month(t1_, label = TRUE),
    
    season = case_when(
      month %in% c("nov","dec", "janv", "febr") ~ 1, #winter
      month %in% c("marts", "apr", "maijs") ~ 2, #spring
      month %in% c("jūn", "jūl", "aug") ~ 3 #summer
    )
  ) %>%
  select(-sunrise, -sunset, -dawn, -dusk, -lon, -lat)


moose_lines <- moose_sf %>%
  group_by(id) %>%
  summarize(do_union = FALSE) %>%
  st_cast("LINESTRING")



```



```{r all moose}

# remove for each moose if burst < 3
dat3 <- dat2 %>%
  mutate(dat.filtered = map(dat.resample, ~ filter_min_n_burst(., min_n = 3)))
# try to retain the filtered AND the id columns
all_moose <- map2_dfr(dat3$dat.filtered, dat3$id, ~{
  .x %>% mutate(id = .y)
})
# again it wants to remove the id, so make map
burst_id_map <- all_moose %>%
  select(id, burst_) %>%
  distinct()
# regular generation of steps
steps <- all_moose %>%
  steps_by_burst() %>%
  random_steps(n_control = 10, 
              sl_distr = fit_distr(.$sl_, "gamma"),
              ta_distr = fit_distr(.$ta_, "vonmises"), 
              include_observed = TRUE) %>% 
  remove_incomplete_strata()

# try to join back the moose id to have for glmmm as random effect
steps <- steps %>%
  left_join(burst_id_map, by = "burst_", relationship = "many-to-one", multiple = "first")

steps2 <- steps %>% 
  extract_covariates(landuse) %>% 
  extract_covariates(new_forest) %>% 
  extract_covariates(major_roads_dist) %>%
  extract_covariates(minor_roads_dist) %>%
  extract_covariates(local_roads_dist)


#  time categories
steps2 <- steps2 %>%
  mutate(
    time_of_day = chron(times = format(t1_, format = "%H:%M:%S")),
    date = as.Date(t1_, format = "%Y/%m/%d")
  ) 

sunlight <- getSunlightTimes(
  date = steps2$date,
  lon = 25.45, 
  lat = 59.05, 
  keep = c("sunrise", "sunset", "dawn", "dusk"),
  tz = "Europe/Tallinn"
)

steps3 <- steps2 %>%
  left_join(sunlight, by = "date", relationship = "many-to-many", multiple = "first") %>%
  mutate(
    sunrise = chron(times = format(sunrise, format = "%H:%M:%S")),
    sunset = chron(times = format(sunset, format = "%H:%M:%S")),
    dawn = chron(times = format(dawn, format = "%H:%M:%S")),
    dusk = chron(times = format(dusk, format = "%H:%M:%S")),
    
    time_category = case_when(
      time_of_day >= sunrise & time_of_day < sunset ~ "Day", # day
      (time_of_day >= dawn & time_of_day < sunrise) | 
        (time_of_day >= sunset & time_of_day < dusk) ~ "Twilight", # twilight
      TRUE ~ "Night"), #night
    
    month = lubridate::month(t1_, label = TRUE),
    
    season = case_when(
      month %in% c("Nov","Dec", "Jan", "Feb") ~ "Winter", #winter
      month %in% c("Mar", "Apr", "May") ~ "Spring", #spring
      month %in% c("Jun", "Jul", "Aug", "Sep") ~ "Summer" #summer
    )
  ) %>%
  select(-sunrise, -sunset, -dawn, -dusk, -lon, -lat)

#joining the categories
# steps3 <- steps3 %>%
#   mutate(
#     sunrise = chron(times = format(sunrise, format = "%H:%M:%S")),
#     sunset = chron(times = format(sunset, format = "%H:%M:%S")),
#     dawn = chron(times = format(dawn, format = "%H:%M:%S")),
#     dusk = chron(times = format(dusk, format = "%H:%M:%S")),
#     
#     time_category = case_when(
#       time_of_day >= sunrise & time_of_day < sunset ~ 1, # day
#       TRUE ~ 3), #night 
#     ) %>%
#   select(-sunrise, -sunset, -dawn, -dusk, -lon, -lat)

# steffanie suggestion how to structure data for injection
d.map <- data.frame(step_id_=unique(steps3$step_id_), 
                    str_ID=1:length(unique(steps3$step_id_)))

# put new sequential stratum ID
steps3$str_ID <- d.map[match(steps3$step_id_, d.map$step_id_), "str_ID"]

# Order data by stratum ID
steps3 <- steps3[order(steps3$str_ID),]

```



```{r base movement model}

steps3$landuse_factor <- factor(steps3$landuse,
                                labels = c("Human-modified", "Deciduous",
                                           "Coniferous", "Mixed", "Open/shrub/bog")) %>% 
  relevel(ref = "Coniferous")


# 1 = human-modified = agriculture and anthropogenic
# 2 = broad-leaved (deciduous)
# 3 = coniferous
# 4 = mixed
# 5 = open areas -> combine with shrub and peatbog and water



# Base Movement and Habitat Selection Model

model_base1 <- fit_issf(
  data = steps3, 
  formula = case_ ~ landuse_factor + factor(new_forest) + 
    log(sl_) + I(log(sl_)^2) + cos(ta_) +
    log(sl_):landuse_factor + cos(ta_):landuse_factor +
    strata(step_id_)
)

summary(model_base1)
AIC_base1 <- AIC(model_base1)
AIC_base1
# [1] 83959.01


#----------------------------------------------------- glmm ----------------------------------------------------

# attempt glmm
steps3$log_sl_ <- scale(log(steps3$sl_))
steps3$cos_ta_ <- scale(cos(steps3$ta_))
steps3$minor_d <- scale(steps3$minor_d)
steps3$major_d <- scale(steps3$major_d)
steps3$local_d <- scale(steps3$local_d)

# Define GLMM structure without fitting
TMBStruc2 <- glmmTMB(
  case_ ~ log_sl_ + cos_ta_ + 
    minor_d + major_d + local_d + 
    landuse_factor +
    (1 | str_ID) +   
    (1 | id), 
  family = poisson,
  data = steps3,
  doFit = FALSE
)

TMBStruc2$parameters$theta[1] = log(1e3)  

TMBStruc2$mapArg = list(theta = factor(c(NA, 1)))

model_glmm2 <- glmmTMB:::fitTMB(TMBStruc2)

summary(model_glmm2)
# 
#       AIC       BIC    logLik  deviance  df.resid 
#  364600.9  364712.9 -182289.4  364578.9    194810 
# 
# Random effects:
# 
# Conditional model:
#  Groups Name        Variance  Std.Dev. 
#  str_ID (Intercept) 1.000e+06 1000.0000
#  id     (Intercept) 1.466e-01    0.3829
# Number of obs: 194821, groups:  str_ID, 17711; id, 8
# 
# Conditional model:
#                               Estimate Std. Error z value Pr(>|z|)    
# (Intercept)                  -2.935093   7.516893  -0.390  0.69619    
# log_sl_                       0.135944   0.008303  16.372  < 2e-16 ***
# cos_ta_                       0.006223   0.007926   0.785  0.43241    
# minor_d                       0.389595   0.093601   4.162 3.15e-05 ***
# major_d                       0.051157   0.098450   0.520  0.60333    
# local_d                       0.105891   0.023514   4.503 6.69e-06 ***
# landuse_factorHuman-modified -0.447389   0.048708  -9.185  < 2e-16 ***
# landuse_factorDeciduous       0.220625   0.058205   3.790  0.00015 ***
# landuse_factorMixed           0.008961   0.036493   0.246  0.80603    
# landuse_factorOpen/shrub/bog  0.001579   0.040038   0.039  0.96854 

#------------------------------------------------------------------season -------------------------------------
# Define GLMM structure without fitting
TMBStruc3 <- glmmTMB(
  case_ ~ log_sl_ + cos_ta_ + 
    minor_d + major_d + local_d + 
    landuse_factor +
    factor(season):minor_d + factor(season):major_d + factor(season):local_d +
    (1 | str_ID) +   
    (1 | id), 
  family = poisson,
  data = steps3,
  doFit = FALSE
)

TMBStruc3$parameters$theta[1] = log(1e3)  

TMBStruc3$mapArg = list(theta = factor(c(NA, 1)))

model_glmm3 <- glmmTMB:::fitTMB(TMBStruc3)

summary(model_glmm3)
# 
#       AIC       BIC    logLik  deviance  df.resid 
#  364586.4  364759.4 -182276.2  364552.4    194804 
# 
# Random effects:
# 
# Conditional model:
#  Groups Name        Variance  Std.Dev. 
#  str_ID (Intercept) 1.000e+06 1000.0000
#  id     (Intercept) 1.492e-01    0.3862
# Number of obs: 194821, groups:  str_ID, 17711; id, 8
# 
# Conditional model:
#                               Estimate Std. Error z value Pr(>|z|)    
# (Intercept)                  -2.930233   7.516954  -0.390 0.696672    
# log_sl_                       0.136254   0.008306  16.405  < 2e-16 ***
# cos_ta_                       0.006218   0.007929   0.784 0.432906    
# minor_d                       0.384017   0.159835   2.403 0.016280 *  
# major_d                       0.165209   0.169520   0.975 0.329772    
# local_d                       0.139183   0.040556   3.432 0.000599 ***
# landuse_factorHuman-modified -0.456627   0.048841  -9.349  < 2e-16 ***
# landuse_factorDeciduous       0.230805   0.058270   3.961 7.47e-05 ***
# landuse_factorMixed           0.011734   0.036521   0.321 0.747991    
# landuse_factorOpen/shrub/bog  0.011550   0.040094   0.288 0.773297    
# minor_d:factor(season)Summer  0.079400   0.223164   0.356 0.721997    
# minor_d:factor(season)Winter -0.009270   0.234461  -0.040 0.968460    
# major_d:factor(season)Summer -0.259332   0.234999  -1.104 0.269790    
# major_d:factor(season)Winter -0.073705   0.247966  -0.297 0.766285    
# local_d:factor(season)Summer  0.068997   0.055190   1.250 0.211238    
# local_d:factor(season)Winter -0.213957   0.059158  -3.617 0.000298 ***


# ---------------------------------------------------------- time ----------------------------------------------
TMBStruc4 <- glmmTMB(
  case_ ~ log_sl_ + cos_ta_ + 
    minor_d + major_d + local_d + 
    landuse_factor +
    factor(time_category):minor_d + factor(time_category):major_d + factor(time_category):local_d +
    (1 | str_ID) +   
    (1 | id), 
  family = poisson,
  data = steps3,
  doFit = FALSE
)

TMBStruc4$parameters$theta[1] = log(1e3)  

TMBStruc4$mapArg = list(theta = factor(c(NA, 1)))

model_glmm4 <- glmmTMB:::fitTMB(TMBStruc4)

summary(model_glmm4)

# 
#       AIC       BIC    logLik  deviance  df.resid 
#  364584.5  364757.6 -182275.3  364550.5    194804 
# 
# Random effects:
# 
# Conditional model:
#  Groups Name        Variance  Std.Dev. 
#  str_ID (Intercept) 1.000e+06 1000.0000
#  id     (Intercept) 1.491e-01    0.3861
# Number of obs: 194821, groups:  str_ID, 17711; id, 8
# 
# Conditional model:
#                                        Estimate Std. Error z value Pr(>|z|)    
# (Intercept)                           -2.937849   7.516933  -0.391 0.695922    
# log_sl_                                0.136662   0.008309  16.448  < 2e-16 ***
# cos_ta_                                0.006293   0.007929   0.794 0.427416    
# minor_d                                0.369509   0.135090   2.735 0.006233 ** 
# major_d                               -0.042561   0.141657  -0.300 0.763835    
# local_d                                0.215358   0.033172   6.492 8.46e-11 ***
# landuse_factorHuman-modified          -0.455815   0.048825  -9.336  < 2e-16 ***
# landuse_factorDeciduous                0.222483   0.058210   3.822 0.000132 ***
# landuse_factorMixed                    0.010424   0.036523   0.285 0.775321    
# landuse_factorOpen/shrub/bog           0.006071   0.040050   0.152 0.879521    
# minor_d:factor(time_category)Night     0.125386   0.202175   0.620 0.535133    
# minor_d:factor(time_category)Twilight -0.128599   0.286251  -0.449 0.653249    
# major_d:factor(time_category)Night     0.290574   0.213288   1.362 0.173085    
# major_d:factor(time_category)Twilight -0.095513   0.299332  -0.319 0.749660    
# local_d:factor(time_category)Night    -0.256509   0.050620  -5.067 4.03e-07 ***
# local_d:factor(time_category)Twilight -0.118236   0.070842  -1.669 0.095114 . 

```

# ---------------------------- IGNORE AFTER THIS -------------------------------------------------------


```{r other models}
# # how movement parameters interact with road proximity
# model_movement <- fit_issf(
#   data = steps3, 
#   formula = case_ ~ minor_d + major_d + local_d + log(sl_) + cos(ta_) + 
#     factor(landuse) + sl_:minor_d + sl_:major_d + sl_:local_d + 
#     strata(step_id_)
# )
# 
# summary(model_movement)


#------------------------------------------------- making road crossing detection -----------------------

steps3$row_id <- 1:nrow(steps3)

steps_lines <- st_sf(
  geometry = mapply(
    function(x1, y1, x2, y2) {
      st_linestring(matrix(c(x1, y1, x2, y2), ncol = 2, byrow = TRUE))
    },
    steps3$x1_, steps3$y1_, steps3$x2_, steps3$y2_,
    SIMPLIFY = FALSE
  ),
  row_id = steps3$row_id,
  step_id_ = steps3$step_id_,
  case_ = steps3$case_,
  crs = 3301
) 


# data frame with crossing information
crossing_data <- data.frame(
  row_id = steps_lines$row_id,
  crosses_major = lengths(st_intersects(steps_lines, roads[roads$class >= 2, ])) > 0,
  crosses_minor = lengths(st_intersects(steps_lines, roads[roads$class == 1, ])) > 0,
  crosses_local = lengths(st_intersects(steps_lines, roads[roads$class == 0, ])) > 0
)

#crossing information back to steps3
steps3 <- merge(steps3, crossing_data, by = "row_id", all.x = TRUE)

table(steps3$crosses_major)
table(steps3$crosses_minor)
table(steps3$crosses_local)


# --------------------- model with crossings -------------------------------


# -------------------------------------------------------------------- crossing  -------------

# Define GLMM structure without fitting
TMBStruc22 <- glmmTMB(
  case_ ~ log_sl_ + cos_ta_ + 
    crosses_minor + crosses_major + crosses_local + 
    landuse_factor +
    (1 | str_ID) +   
    (1 | id), 
  family = poisson,
  data = steps3,
  doFit = FALSE
)

TMBStruc22$parameters$theta[1] = log(1e3)  

TMBStruc22$mapArg = list(theta = factor(c(NA, 1)))

model_glmm22 <- glmmTMB:::fitTMB(TMBStruc22)

summary(model_glmm22)

#       AIC       BIC    logLik  deviance  df.resid 
#  364523.2  364635.2 -182250.6  364501.2    194810 
# 
# Random effects:
# 
# Conditional model:
#  Groups Name        Variance  Std.Dev. 
#  str_ID (Intercept) 1.000e+06 1000.0000
#  id     (Intercept) 1.528e-01    0.3909
# Number of obs: 194821, groups:  str_ID, 17711; id, 8
# 
# Conditional model:
#                               Estimate Std. Error z value Pr(>|z|)    
# (Intercept)                  -2.889117   7.517020  -0.384   0.7007    
# log_sl_                       0.152736   0.008532  17.902  < 2e-16 ***
# cos_ta_                       0.009919   0.007932   1.251   0.2111    
# crosses_minorTRUE             0.430581   0.217417   1.980   0.0477 *  
# crosses_majorTRUE            -1.064889   0.244930  -4.348 1.38e-05 ***
# crosses_localTRUE            -0.396981   0.045602  -8.705  < 2e-16 ***
# landuse_factorHuman-modified -0.497643   0.048607 -10.238  < 2e-16 ***
# landuse_factorDeciduous       0.235597   0.058366   4.037 5.42e-05 ***
# landuse_factorMixed          -0.029234   0.036510  -0.801   0.4233    
# landuse_factorOpen/shrub/bog -0.039269   0.040255  -0.976   0.3293  

#------------------------------------------------------------------season 2: with crossing --------------------------
# Define GLMM structure without fitting
TMBStruc33 <- glmmTMB(
  case_ ~ log_sl_ + cos_ta_ + 
    crosses_minor + crosses_major + crosses_local + 
    landuse_factor +
    factor(season):crosses_minor + factor(season):crosses_major + factor(season):crosses_local +
    (1 | str_ID) +   
    (1 | id), 
  family = poisson,
  data = steps3,
  doFit = FALSE
)

TMBStruc33$parameters$theta[1] = log(1e3)  

TMBStruc33$mapArg = list(theta = factor(c(NA, 1)))

model_glmm33 <- glmmTMB:::fitTMB(TMBStruc33)

summary(model_glmm33)

#       AIC       BIC    logLik  deviance  df.resid 
#  364519.3  364712.7 -182240.6  364481.3    194802 
# 
# Random effects:
# 
# Conditional model:
#  Groups Name        Variance  Std.Dev. 
#  str_ID (Intercept) 1.000e+06 1000.0000
#  id     (Intercept) 1.852e-01    0.4303
# Number of obs: 194821, groups:  str_ID, 17711; id, 8
# 
# Conditional model:
#                                          Estimate Std. Error z value Pr(>|z|)    
# (Intercept)                             -2.805462  12.928231  -0.217 0.828206    
# log_sl_                                  0.152628   0.008531  17.890  < 2e-16 ***
# cos_ta_                                  0.010191   0.007933   1.285 0.198949    
# crosses_minorTRUE                        0.552465   0.319454   1.729 0.083737 .  
# crosses_majorTRUE                       -0.595107   0.358432  -1.660 0.096853 .  
# crosses_localTRUE                       -0.276450   0.077844  -3.551 0.000383 ***
# landuse_factorHuman-modified            -0.499699   0.048623 -10.277  < 2e-16 ***
# landuse_factorDeciduous                  0.233602   0.058356   4.003 6.25e-05 ***
# landuse_factorMixed                     -0.030514   0.036512  -0.836 0.403316    
# landuse_factorOpen/shrub/bog            -0.041978   0.040286  -1.042 0.297416    
# crosses_minorFALSE:factor(season)Summer  0.115324  17.845459   0.006 0.994844    
# crosses_minorTRUE:factor(season)Summer  -1.353534  17.863601  -0.076 0.939602    
# crosses_minorFALSE:factor(season)Winter -0.474857  19.036783  -0.025 0.980099    
# crosses_minorTRUE:factor(season)Winter  -0.203714  19.042630  -0.011 0.991465    
# crosses_majorTRUE:factor(season)Summer  -0.176694   0.543362  -0.325 0.745040    
# crosses_majorTRUE:factor(season)Winter  -1.533119   0.697401  -2.198 0.027925 *  
# crosses_localTRUE:factor(season)Summer  -0.090096   0.105826  -0.851 0.394569    
# crosses_localTRUE:factor(season)Winter  -0.298422   0.114455  -2.607 0.009125 ** 

# ---------------------------------------------------------- time 2: with crossings --------------------------------
TMBStruc44 <- glmmTMB(
  case_ ~ log_sl_ + cos_ta_ + 
    crosses_minor + crosses_major + crosses_local + 
    landuse_factor +
    factor(time_category):crosses_minor + factor(time_category):crosses_major + factor(time_category):crosses_local +
    (1 | str_ID) +   
    (1 | id), 
  family = poisson,
  data = steps3,
  doFit = FALSE
)

TMBStruc44$parameters$theta[1] = log(1e3)  

TMBStruc44$mapArg = list(theta = factor(c(NA, 1)))

model_glmm44 <- glmmTMB:::fitTMB(TMBStruc44)

summary(model_glmm44)

#       AIC       BIC    logLik  deviance  df.resid 
#  364525.7  364719.1 -182243.9  364487.7    194802 
# 
# Random effects:
# 
# Conditional model:
#  Groups Name        Variance Std.Dev.
#  str_ID (Intercept) 1.00e+06 1000.000
#  id     (Intercept) 1.73e-01    0.416
# 
# Conditional model:
#                                                   Estimate Std. Error z value Pr(>|z|)    
# (Intercept)                                      -2.493584  10.776294  -0.231   0.8170    
# log_sl_                                           0.152652   0.008533  17.890  < 2e-16 ***
# cos_ta_                                           0.009900   0.007932   1.248   0.2120    
# crosses_minorTRUE                                -0.052670   0.419994  -0.125   0.9002    
# crosses_majorTRUE                                -1.841373   0.589824  -3.122   0.0018 ** 
# crosses_localTRUE                                -0.408808   0.074578  -5.482 4.22e-08 ***
# landuse_factorHuman-modified                     -0.498646   0.048632 -10.254  < 2e-16 ***
# landuse_factorDeciduous                           0.234875   0.058379   4.023 5.74e-05 ***
# landuse_factorMixed                              -0.029332   0.036517  -0.803   0.4218    
# landuse_factorOpen/shrub/bog                     -0.038921   0.040264  -0.967   0.3337    
# crosses_minorFALSE:factor(time_category)Night    -0.739037  16.215502  -0.046   0.9636    
# crosses_minorTRUE:factor(time_category)Night     -0.132759  16.223472  -0.008   0.9935    
# crosses_minorFALSE:factor(time_category)Twilight -0.732099  23.523036  -0.031   0.9752    
# crosses_minorTRUE:factor(time_category)Twilight   0.465979  23.535007   0.020   0.9842    
# crosses_majorTRUE:factor(time_category)Night      0.923753   0.668422   1.382   0.1670    
# crosses_majorTRUE:factor(time_category)Twilight   1.474727   0.814244   1.811   0.0701 .  
# crosses_localTRUE:factor(time_category)Night     -0.050600   0.097499  -0.519   0.6038    
# crosses_localTRUE:factor(time_category)Twilight   0.296533   0.141770   2.092   0.0365 *  



```



```{r inspect variables}



numeric_predictors <- steps3 %>% select(-"x1_", -"x2_", -"y1_", -"y2_", "burst_", "step_id_")

correlation_matrix <- cor(numeric_predictors, use = "complete.obs")

print(correlation_matrix)

corrplot(correlation_matrix, method = "color", type = "upper", 
         order = "hclust", tl.col = "black", tl.srt = 45,
         diag = FALSE) 



library(polycor)


steps3$crosses_major <- as.factor(steps3$crosses_major)
steps3$crosses_minor <- as.factor(steps3$crosses_minor)
steps3$crosses_local <- as.factor(steps3$crosses_local)
steps3$time_category <- as.factor(steps3$time_category)
steps3$season <- as.factor(steps3$season)

vars_of_interest <- steps3[, c("landuse_factor", "major_d", "minor_d", "local_d", 
                               "time_category", "season", 
                               "crosses_major", "crosses_minor", "crosses_local")]


het_cor <- hetcor(vars_of_interest)
het_cor$correlations
corrplot(het_cor$correlations, method = "color", 
         type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)
```



```{r Stefanie example, not accessible currently.. just paste}
#'---
#'title: RSF and SSF analysis of fisher 
#'author: "S. Muff, J. Signer, J. Fieberg"
#'date: "r format(Sys.time(), '%d %B, %Y')"
#'output:
#'  html_document:
#'    toc: yes
#'---

#+ include = FALSE
knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = TRUE)

#' ## Purpose
#' The purpose of this document is to illustrate how a simple RSF and SSF with random effects can be fitted to tracking data. We use a data set containing fisher locations from:
#' 
#' - LaPoint, S., Gallery, P., Wikelski, M. and Kays, R. (2013). Animal behavior, cost-based corridor models, and real corridors. Landscape Ecology, 28, 1615-1630.
#' 

#' ## Load libraries and prepare data
#+ echo=TRUE, message=FALSE, warning=FALSE
library(glmmTMB)
library(INLA)
library(tidyverse)
library(raster)
library(survival)
library(TwoStepCLogit)
library(amt)

#' First load the fisher data (this is the data as it was downloaded from movebank).
#' We simplified the fisher data slightly, by running the following code prior to upload the data (to save space). This code is not needed, unless you download the original data from: https://www.datarepository.movebank.org/handle/10255/move.330.
#+ eval=FALSE
dat <- read_csv("Martes pennanti LaPoint New York.csv") %>% 
  filter(!is.na(location-lat)) %>% 
  select(x = location-long, y = location-lat, 
         t = timestamp, id = tag-local-identifier) %>% 
  filter(id %in% c(1465, 1466, 1072, 1078, 1016, 1469))
write_csv(dat, "Fisher_analysis/fisher_data.csv")

#' Now lets start by reading in the simplified fisher data

dat <- read_csv("fisher_data.csv")

#' Include sex of each animal and create tracks with an appropriate coordinate reference system using the amt package
dat_all <- dat %>% nest(-id) 
dat_all$sex <- c("f", "f", "f", "m", "m", "m")
dat_all <- dat_all %>% 
  mutate(trk = map(data, function(d) {
    make_track(d, x, y, t, crs = sp::CRS("+init=epsg:4326")) %>% 
      transform_coords(sp::CRS("+init=epsg:5070"))
  }))

#' Summarize sampling rates, 
dat_all %>% mutate(sr = lapply(trk, summarize_sampling_rate)) %>% 
  select(id, sr) %>% unnest

#' 10 minutes seems to appropriate for all animals.
#' Resample the track to 10 minutes with a tolerance of 2 minutes.

dat1 <- dat_all %>% mutate(dat_clean = map(trk, ~ {
  .x %>% track_resample(rate = minutes(10), tolerance = seconds(120))
  }))

#' Read in the landuse raster and reclassify to two categories (wet forests and other).
landuse <- raster("landuse_study_area.tif")
wet_forests <- landuse %in% c(90, 95)
names(wet_forests) <- "forest"

#' # Resource Selection Functions (RSF)
#' 
#' ## Data development for RSF
#' 
#' Now start with an RSF by creating random points per animal and extract the covariates for the observed and random points.

dat_rsf <- dat1 %>% mutate(rp = map(dat_clean, ~ .x %>% random_points() %>% 
      extract_covariates(wet_forests))) %>% 
  select(id, rp) %>%  unnest()
#' Change id column, to 1:6
dat_rsf$id <- as.numeric(factor(dat_rsf$id))

#' Make response numeric (required for INLA)
dat_rsf$y <- as.numeric(dat_rsf$case_)

#' We use a weighted likelihood for to fit the RSF. To this end, we need to create a variable for the weights, where used points (case_ = TRUE) keep weight 1, and available points (case_ = FALSE) obtain a large weight $W$ (here $W=1000$):
#+ echo=TRUE, message=FALSE
dat_rsf$weight <- 1000^(1 - dat_rsf$case_)

#' ## Mixed RSFs
#' 
#' ### glmmTMB()
#' 
#' 
#' As explained in the manuscript (Section 3.4), we recommend to manually fix the variance of the random intercept at a large value. This can be done in glmmTMB() by first setting up the model, but do not yet fit it:
#+ echo=TRUE, message=FALSE,cache=TRUE
fisher.tmp <- glmmTMB(case_ ~ forest + (1|id) + (0 + forest |id) , family=binomial(), data = dat_rsf,
                         doFit=FALSE, weights = weight)


#' Then fix the standard deviation of the first random term, which is the (1|id) component  in the above model equation. We use $\sigma=10^3$, which corresponds to a variance of $10^6$:
#+ echo=TRUE, message=FALSE,cache=TRUE
fisher.tmp$parameters$theta[1] <- log(1e3)


#' We need to tell glmmTMB not to change the first entry of the vector of variances, and give all other variances another indicator to make sure they can be freely estimated:
#+ echo=TRUE, message=FALSE,cache=TRUE
fisher.tmp$mapArg <- list(theta=factor(c(NA, 1)))

#' Then fit the model and look at the results:
#+ echo=TRUE, message=FALSE, cache=TRUE 
fisher.rsf <- glmmTMB:::fitTMB(fisher.tmp)
summary(fisher.rsf)


#' ###  INLA 
#'
#' Let us now carry the analysis with random intercept $\mathsf{N}(0,\sigma_{id}^2)$ and fixed variance $\sigma_{id}^2=10^6$ using INLA. A peculiarity of INLA is that the same variable cannot be used more than once. So for ID we need to generate a new (but identical) variable
#+ echo=TRUE, message=FALSE
dat_rsf$id1 <-dat_rsf$id

#' For the fixed effects we use the INLA (default) priors $\beta \sim \mathsf{N}(0,\sigma_\beta^2)$ with $\sigma_\beta^2=10^4$. The precisions of the priors are thus set to:
#+ echo=TRUE, message=FALSE
prec.beta.forest  <- 1e-4  

#' We now store the INLA formula with the fixed effects forest, plus two random effects, namely one for the individual-specific intercept and one for the individual-specific slope for forest. Note that the precision (thus $1/\sigma^2$) for id is fixed (fixed=TRUE) at the value of $10^{-6}$ (thus the variance is fixed at $10^6$). The other precision is given a PC(1,0.05) prior:
#+ echo=TRUE, message=FALSE
formula.inla <- y ~  forest + 
  f(id, model="iid", hyper=list(theta = list(initial=log(1e-6),fixed=TRUE))) +
  f(id1,forest,values=1:6,model="iid",
    hyper=list(theta=list(initial=log(1),fixed=F,prior="pc.prec",param=c(1,0.05)))) 


#' The actual INLA call is then given as follows:
#+  echo=TRUE, message=FALSE, cache=TRUE
inla.setOption(enable.inla.argument.weights=TRUE)
fisher.inla  <- inla(formula.inla, family ="binomial", data=dat_rsf, weights=dat_rsf$weight,
                        control.fixed = list(
                          mean = 0,
                          prec = list(forest = prec.beta.forest)
                       )
)



#' The summary for the posterior distribution of the fixed effects is given as follows:
#+ echo=TRUE
fisher.inla$summary.fixed


#' Since variances are parameterized and treated as precisions, the summary of the respective posterior distributions is given for the precisions:
#+ echo=TRUE
fisher.inla$summary.hyperpar


#' Source R functions for calculating posterior means 
#' and medians of the precisions.
source("inla_emarginal.R")
source("inla_mmarginal.R")
inla_emarginal(fisher.inla)
inla_mmarginal(fisher.inla)



#' # Step-Selection Function (SSF)
#' 
#' ## Data development for step-selection function
#' 
#' First we need to prepare the data. We need to pair each observed point with 10 random points and extract the covariate value at the end point of each step.

#+ warning = FALSE
dat_ssf <- dat1 %>% 
  mutate(stps = map(dat_clean, ~ .x %>% steps_by_burst() %>% 
                      random_steps() %>% extract_covariates(wet_forests))) %>% 
  select(id, stps) %>% unnest() %>% 
  mutate(
    y = as.numeric(case_),
    id = as.numeric(factor(id)), 
    step_id = paste0(id, step_id_, sep = "-"))
dat_ssf


#' ## Mixed SSFs 

#' ### 2StepCLogit 

#' The two-step procedure with independent random effect (D="UN(1)"):
r.Twostep <-  Ts.estim(formula = y ~ forest + strata(step_id) + 
                     cluster(id), data = dat_ssf, random = ~ forest,
                   all.m.1=F, D="UN(1)") 

#' Slope estimates and standard errors
r.Twostep$beta
r.Twostep$se

#' Variance estimates
r.Twostep$D

#' ### glmmTMB


#' ## Session Info
#'
devtools::session_info()


#'---
#' title: Habitat selection of otters (an SSF analysis)
#' author: "S. Muff, J. Signer, J. Fieberg"
#' date: "r format(Sys.time(), '%d %B, %Y')"
#' output:
#'   html_document: 
#'     toc: true
#'---
#'
#+ include = FALSE
knitr::opts_chunk$set(warning = FALSE, message = FALSE, cache = TRUE)
#'  
#' **Purpose**: This code replicates the analysis presented in Muff, Signer, Fieberg (2019) Section 4.2 "Habitat selection of otters: an SSF analysis".
#'

#' ## Load libraries and read in data
#+ warning=FALSE, message=FALSE
library(survival)
library(TwoStepCLogit)
library(INLA)
library(glmmTMB)
options(width=150)
dat <-  read.csv("d_otter.csv")
str(dat)

#' NAT1, REST1 and STAU1 are the three factor levels of the factor variable habitat type, encoded as dummy variables, where
#'
#' - NAT1: natural habitat (reference category)
#' - REST1: residual water
#' - STAU1: a reservoir
#'
#' Further, the two continuous variables in the model are:
#' 
#' - Sohlbrei: the river width
#' - Breaks_Dis: step length
#' 
#' Finally, Loc is the binary response variable that indicates if a habitat point was used (1) or available (0).
#'
#' ### Some data manipulation:

#' Add numerical variable for animals:
dat$ANIMAL_ID <- as.numeric(as.factor(dat$NA_ANIMAL))

#' Stratum ID is given as "NA_ID" in the data; 
#' It is easier to have sequential enumeration, so let's generate a new stratum-ID variable str_ID:
d.map <- data.frame(NA_ID=unique(dat$NA_ID),str_ID=1:length(unique(dat$NA_ID)))
dat$str_ID <- d.map[match(dat$NA_ID,d.map$NA_ID),"str_ID"]
dat <- dat[order(dat$str_ID),]

#' Scale and center the two continuous variables river width (Sohlenbrei) and step length (Breaks_Dis)
dat$Sohlenbrei <- scale(dat$Sohlenbrei)
dat$Breaks_Dis <- scale(dat$Breaks_Dis)


#' ## Fixed effects models 
 
#' ### clogit
r.clogit <- clogit(Loc ~ STAU1 + REST1 + Sohlenbrei + Breaks_Dis  
                   +   strata(str_ID), data=dat) 

summary(r.clogit)$coef

```

